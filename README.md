# Dynamic-live Neural Networks
Dynamic-Live neural networks are type of RNN. However, they differ in an important way, the connections between each neuron is learnable. When a neuron is created it is not connected to anything. After every neuron we want to have in total is created we call a function and pass it a list of neurons. We do this for each neuron in our network. That list is every neuron that the particular neuron is allowed to get input from. The network learns how to form good connections between every neuron.

## How does it work?
The main feature of this network is not yet finished, we are still in the phase of creating basic functionalities such as the training functions. A lot of these things are harder to implement because of the nature of the network. Below is what training the network looks like as of now.
### Input propagation
This is how basic predictions are made in this network. Just about any other neural network implements this in some for or another. This is a single function in our library.
#### Priming
This makes the neuron go and get its inputs from each connected neuron. We can't get the inputs when we fire the neurons because doing so would cause some problems with the data that the neurons get, depending on the order that they are fired.
#### Firing
When a neuron fires it takes the dot product of the weights stored in the neuron and the inputs we got in the priming step, averages all the dot products, then is passed to an activation function of the users design (custom activations supported) and the output of the neuron is stored in a variable. Note that the input to the function will always be between 0 and 1. This network does not work with negative inputs or outputs. This is repeated for every layer in order. It's worth noting that layering is only used to tell the system what order to fire groups of neuron and has nothing to do with what neurons can connect where. After every neuron has fired the output of every neuron in the output layer is gathered into an array and returned.
### Backpropagation
We do reinforcment backpropogation on the neuron level. We do not plan to use any form of targeted trianing. Memory data is collected by each neuron during the propogation step. This data does not influence predictions made, it is instead used to get context for training because in complex networks a neurons actions might not display until 5, 50 or even 500 cycles later. When we train the neurons internally reference each others outputs which lets the neurons know what data to look at when training. The neuron sees what output is referenced, looks at each corresponding input it received and uses them to calculate weight changes. This is performed for every input of the neuron. After a neuron has made these changes it rewards each connected neuron based on how much it contributed and calls the same function on it. This chain continues back until it either backpropogations is 0 or until all signals reach the input neuorns as they only take input from the outside world and don't weight anything.
#### Connection strengths
The weights that we just explained work just as normal weights, but they also represent connection strengths. The two terms are synomonious in this system. If a connection strength drops below a user set value (usualy 0) then the connection is removed. After a neuron has made all the changes to it's weights then the weights are nomalized so they all add to 1. This is to represent the max connection strength that the neuron can support and prevents exploding or shrinking weights. 
#### Forming new connections
Connections can be removed, and the strength of the connections can be distributed in any way. So of course it makes sense that new connections can be formed. This is the current area of research. We are looking for computationaly efficient ways that we can search for connections between neurons. If you would like to train a network then it is recommended you start the network out with every possible connection it can have, however note that after a long enough time training it will start to lose capabilitys because it does not have enough connections.
